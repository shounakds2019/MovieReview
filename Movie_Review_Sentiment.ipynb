{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moview Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Set : https://www.kaggle.com/utathya/imdb-review-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Autograding\n",
    "import tests_lab4\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# train test split and cross validation\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Function\n",
    "\n",
    "def store_cross_val_results(model_name, scores, results_dict):\n",
    "    \"\"\"\n",
    "    Stores mean scores from cross_validate in results_dict for\n",
    "    the given model model_name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name :\n",
    "        scikit-learn classification model\n",
    "    scores : dict\n",
    "        object return by `cross_validate`\n",
    "    results_dict: dict\n",
    "        dictionary to store results\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    results_dict[model_name] = {\n",
    "        \"mean_train_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"train_score\"])),\n",
    "        \"mean_valid_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"test_score\"])),\n",
    "        \"mean_fit_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"fit_time\"])),\n",
    "        \"mean_score_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"score_time\"])),\n",
    "        \"std_train_score\": \"{:0.4f}\".format(scores[\"train_score\"].std()),\n",
    "        \"std_valid_score\": \"{:0.4f}\".format(scores[\"test_score\"].std()),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = pd.read_csv(\"imdb_master.csv\", encoding=\"ISO-8859-1\", index_col=\"Unnamed: 0\")\n",
    "imdb_df = imdb_df.query('label == \"neg\" | label == \"pos\"')\n",
    "train_df = imdb_df.query('type == \"train\"')\n",
    "test_df = imdb_df.query('type == \"test\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                             review label         file\n",
       "0  test  Once again Mr. Costner has dragged out a movie...   neg      0_2.txt\n",
       "1  test  This is an example of why the majority of acti...   neg  10000_4.txt\n",
       "2  test  First of all I hate those moronic rappers, who...   neg  10001_1.txt\n",
       "3  test  Not even the Beatles could write songs everyon...   neg  10002_3.txt\n",
       "4  test  Brass pictures (movies is not a fitting word f...   neg  10003_3.txt"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(imdb_df[\"review\"],imdb_df[\"label\"],test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time (s)</th>\n",
       "      <th>mean_score_time (s)</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_valid_accuracy</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>std_valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression(max_iter=2000)</th>\n",
       "      <td>6.4462</td>\n",
       "      <td>2.7904</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.8757</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  mean_fit_time (s) mean_score_time (s)  \\\n",
       "LogisticRegression(max_iter=2000)            6.4462              2.7904   \n",
       "\n",
       "                                  mean_train_accuracy mean_valid_accuracy  \\\n",
       "LogisticRegression(max_iter=2000)              0.9991              0.8757   \n",
       "\n",
       "                                  std_train_score std_valid_score  \n",
       "LogisticRegression(max_iter=2000)          0.0000          0.0020  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict ={}\n",
    "pipeline = make_pipeline(CountVectorizer(binary = True), LogisticRegression(max_iter=2000))\n",
    "scores = cross_validate(pipeline, X_train, y_train, cv=2, return_train_score=True)\n",
    "store_cross_val_results(\"LogisticRegression(max_iter=2000)\", scores, results_dict)\n",
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logistic = make_pipeline(CountVectorizer(binary = True), LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"logisticregression__C\": 10.0 ** np.arange(-3, 3),\n",
    "              \"countvectorizer__max_features\": [10,20,30,100,1000,8000],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                              CountVectorizer(binary=True)),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(max_iter=1000))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'countvectorizer__max_features': [10,\n",
       "                                                                          20,\n",
       "                                                                          30,\n",
       "                                                                          100,\n",
       "                                                                          1000,\n",
       "                                                                          8000],\n",
       "                                        'logisticregression__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])},\n",
       "                   return_train_score=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(pipe_logistic, param_distributions = param_grid, cv = 5, n_jobs = -1, n_iter = 10, return_train_score = True)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'logisticregression__C': 0.01, 'countvectorizer__max_features': 8000}\n",
      "Best Validation Score:  0.8813749999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Params: \",random_search.best_params_)\n",
    "print(\"Best Validation Score: \",random_search.best_score_)\n",
    "#pd.DataFrame(random_search.cv_results_).set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(binary=True, max_features=8000)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.01, max_iter=1000))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words that are most indicative of a positive review:\n",
      "  ['awesome', 'fun', 'definitely', 'dvd', 'enjoyable', 'highly', 'favorite', 'enjoyed', 'hilarious', 'brilliant', 'fantastic', 'best', 'superb', 'today', 'loved', 'wonderful', 'amazing', 'perfect', 'great', 'excellent']\n",
      "\n",
      "words that are most indicative of a negative review:\n",
      "  ['worst', 'waste', 'awful', 'boring', 'bad', 'terrible', 'poor', 'dull', 'poorly', 'worse', 'horrible', 'stupid', 'fails', 'disappointment', 'nothing', 'disappointing', 'unfortunately', 'avoid', 'mess']\n"
     ]
    }
   ],
   "source": [
    "weights_neg_20 = np.argsort(random_search.best_estimator_.named_steps['logisticregression'].coef_.flatten())[0:19:1]\n",
    "weights_pos_20 = np.argsort(random_search.best_estimator_.named_steps['logisticregression'].coef_.flatten())[-20:]\n",
    "\n",
    "neg = []\n",
    "pos = []\n",
    "\n",
    "words = random_search.best_estimator_.named_steps['countvectorizer'].get_feature_names()\n",
    "\n",
    "for index in weights_neg_20:\n",
    "    neg.append(words[index])\n",
    "    \n",
    "for index in weights_pos_20:\n",
    "    pos.append(words[index])\n",
    "    \n",
    "print(\"words that are most indicative of a positive review:\\n \", pos)\n",
    "print(\"\\nwords that are most indicative of a negative review:\\n \", neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Best estimator in Logistic Regression:  0.8777\n"
     ]
    }
   ],
   "source": [
    "random_search.best_estimator_.fit(X_train,y_train)\n",
    "scores = random_search.best_estimator_.score(X_test,y_test)\n",
    "print(\"Accuracy Score of Best estimator in Logistic Regression: \",scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_neg = np.where(random_search.best_estimator_.predict_proba(X_test)[:,0] == max(random_search.best_estimator_.predict_proba(X_test)[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With associated probability score of:  0.9999989498597482 \n",
      "the review with highest predicted probability of being negative is: \n",
      "\n",
      " Plankton, or Creatures from the Abyss as I'm positive it's more commonly known as & filmed under as the title Creatures from the Abyss appears over a moving image & in the same font type as the rest of the credits, starts with five 20 something kids, Mike (Clay Rogers) his girlfriend Margaret (Sharon Twomey), sisters Julie (Ann Wolf) & Dorothy (Loren DePalm) & an annoying idiot named Bobby (Michael Bon) whom decide to all fit into a small rubber boat & head out to sea, don't ask why as I don't know. Oh & the complete idiot Bobby left the petrol behind & never thought to tell anyone so it comes as no great surprise that they end up stranded out at sea without any petrol for the motor & to make matters worse they become trapped in a thunder storm & discover a dead body floating in the water. Shortly after their luck seems to change when they come across a yacht & potential safety, in a flash everyone boards the yacht & begin to explore. First of all they find a scientific lab with various fish specimens & computer equipment, then down below they find fully furnished & luxurious cabins. They find a chemist (Deran Sarafian) who appears mad & can't talk. They eat fish from the fridge which makes Dorothy puke up green vomit, beetles & slugs. They learn that these fish are living fossil's 1000's of years old & have been contaminated by toxic waste dumped in the sea & that they fly, mutate, bite & are generally unpleasant to be around. I really can't be bothered to go on with this plot outline so I won't, here's what I think...<br /><br />This Italian production was produced & directed by Massimiliano Cerchi under the pseudonym Al Passeri (I'd hide under a different name if I made a film this bad too) & I think Plankton is quite simply one of the worst films ever, there are so many things wrong with this film it's difficult to know where to start. First the script by Richard Baumann is total crap, it makes no sense whatsoever & is so slow & dull it was torture for me to sit through. Why would five people just simply set sail for the middle of the ocean on a rubber dinghy barely big enough to fit them all in? What were they planning on doing exactly? Why do we often get point-of-view shots from these fish creatures but they seem to be totally invisible to the characters as they are never shown on screen even though they are right next to a character, & how do these fish get around the boat as there is no water for them to swim in? People's actions & reactions to things are all wrong, they constantly split up, they make bizarre decisions that simply don't make any sense in the situation they find themselves in & some of the dialogue is as awful as anything I've heard. I could go on all day about all the plot holes & ridiculous goings on but I'll run out of space if I do. The fish creatures themselves look awful, a mixture of rubbish rubber puppets & some really bad stop motion animation at the end, the scenes where they interact with the human cast also look terrible with some bad super imposition. I have heard a lot of comments saying that Plankton is gory, don't make me laugh! Forget it there is virtually no blood or gore in Plankton whatsoever, there are a couple of slimy scenes when Bobby transforms into a fish monster while having sex with Julie but it's pretty brief & he doesn't kill her, he just sort of drips slime on her, grows a couple of tentacles & a fish head comes out of his mouth. Later on Julie's vagina starts to drip some dark slime but that's it, we never get to actually see what happens to her or what the slime is. Dorothy has a fish creature come out of her back, off screen, & control her but again we never get to see what happens to her while Margaret commits suicide, a very brief shot of a plastic harpoon stuck to her forehead. Easily the grossest scene is when Dorothy pukes up that green stuff with what looks like beetles & slugs in it. That's it, only one person actually dies on screen & for the most part Plankton is quite tame & as exciting as watching paint dry & I nearly fell asleep it's so boring. I can't see how anybody can like this total crap, I just can't. The acting is awful, the dubbing is awful, the characters are awful & I hated all of them. Tecnically Plankton is predictably crap as well, with an estimated budget of only $250,000 all I can say is where did the money go? The sets are monotonous & dull with one lab & a few cabins, the special effect's are bottom of the barrel stuff including the most fake looking exploding boat ever, the cinematography is bland, the music sucks there is zero atmosphere or tension & as a whole Plankton, like it's name sake, is as low in the food chain as it could possibly be. I hate Plankton, it's awful in every single aspect of it's overlong 86 minute duration. Do yourself a favour & avoid this one at all costs unless your either a masochist or insomniac.\n"
     ]
    }
   ],
   "source": [
    "print(\"With associated probability score of: \",max(random_search.best_estimator_.predict_proba(X_test)[:,0]),\n",
    "      \"\\nthe review with highest predicted probability of being negative is: \\n\\n\",X_test.iloc[int(most_neg[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_pos = np.where(random_search.best_estimator_.predict_proba(X_test)[:,1] == max(random_search.best_estimator_.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With associated probability score of:  0.9999879729486912 \n",
      "the review with highest predicted probability of being positive is: \n",
      "\n",
      " I am beginning to see a very consistent pattern form in the identity of 2007's films. If 2004 was the year of the biographies and 2005 was the year of the political films, 2007 can be identified as a year featuring a wide plethora of morality tales, films that portray, test, challenge and question human morality and the motives that drive us to do certain things. Although this identification is rather broad, I think that there are a handful of films released this year, such as 3:10 To Yuma, Eastern Promises, American Gangster, No Country for Old Men and others that specifically question and study human morals and the motives that drive us to acts such as violence or treachery. Before the Devil Knows You're Dead is a deviously stylish morality tale, and quite a dark, bleak and depressing one at that. And even better is the fact that it comes from one of the greatest classic directorial forces of our time, the legendary Sidney Lumet, who many have said has passed his prime but returns in full force with this viciously rich crime thriller.<br /><br />It's one of those films whose plots are so thick, that one is very reluctant to go into details. It is a movie that is best enjoyed if entered without any prior knowledge to the events about to unfold, as there are twists and turns. But the thick and richly wrought plot is not at all at the center of this film; the true focus is, as I mentioned, the morality tale; the motives that drive these two men to the actions they do in the film. In a plot structured like a combination between the filmographies of both The Coen Brothers (namely Blood Simple and Fargo) and Quentin Tarantino, we see two men driven under various shady circumstances to pull off a fairly simple crime that goes incredibly, ridiculously wrong, and reciprocates with full force and inevitable tragedy. And to make it all the more interesting, the film is told in a fragmented chronology that keeps back tracking and showing a series of events following a different character every time and always ending up where it left off the last time. Sizzling, sharp, thick and precariously depressing, Kelly Masterson's screenplay is surprisingly poignant and well rounded, in particular because it is a debut screenplay.<br /><br />But the film has much more going for it than just it's delectably sinister and quite depressing plot. First and foremost, the picture looks and feels outstandingly well. Sidney Lumet has, throughout his career, consistently employed an interesting style of cinematography and lighting: naturalistic and yet stylish at the same time. The film carries with it a distinctive air of style and class, with wonderful natural lighting that just looks really great. Editing is top-notch; combining the sizzling drama-thriller aspect with great long takes that really take their time to portray the action accordingly. And vivid, dynamic camera angles and movements further add to the style. The film is also backed by a fantastically succulent musical score by Carter Burwell.<br /><br />The screenplay does its part, and of course Lumet does his part, but at the film's dramatic center are three masterful actors who deliver incredibly good performances. First and foremost, there are the two leads. Leading the pack is Philip Seymour Hoffman, who has always been an excellent actor but has stumbled upon newfound leading-man status after his unnaturally fantastic Oscar-winning performance in Capote. His turn in this film is fascinating: severely flawed, broken, manic. Hoffman has some truly intense scenes in the film that really allow his full dramatic fury to come out, and not just his subtlety and wit. At his side is Ethan Hawke, who has delivered some fantastic performances in many films that are almost always overshadowed by greater, grander actors. Here, he bounces off Hoffman and complements him so incredibly well; in all, the dynamic acting between the two of them is just so utterly fantastic and convincing, the audience very quickly loses itself in the characters and forgets that it's watching actors. And then there's Albert Finney. Such a supple, opulent supporting role like the one he has requires a veteran professional and here Finney delivers his finest performance in many years as the tragically obsessed father to the two brothers who get caught up in the crime. I love how the dynamics between the three of them play out. I love how Hoffman is clearly the dominant brother and shamelessly picks on his younger brother even now that they're middle-aged men; and yet despite this, it is clear how Finney's father favours Hawke's younger, weaker brother. Also on the topic of the cast, the two supporting female characters Â? wives of the brothers Â? also feature fantastic performances from Amy Ryan and Marisa Tomei, whose looks just get better and better as the years go by.<br /><br />This film isn't revolutionary. These themes and this style have already been explored by the likes of The Coen Brothers, and it's very easy to imagine them directing this film. But for a film that treads familiar ground, it simply excels. Lumet employs his own immense directorial talent and employs his unique and very subtle sense of irony and style to Masterson's brilliantly vivid, intense, and morbidly depressing first-time screenplay. The lead performances are incredibly intense and the film features absolutely fantastic turns from Hoffman, Hawke and Finney; but the truly greatest wonder of the film is that three years after he won a Lifetime Achievement Oscar, much revered as the ultimate sign of retirement in the film business, Sidney Lumet proves that he still has the immense talent to deliver a truly wonderful, resonant, intense piece of cinema reminiscent of his golden years.\n"
     ]
    }
   ],
   "source": [
    "print(\"With associated probability score of: \",max(random_search.best_estimator_.predict_proba(X_test)[:,1]),\n",
    "      \"\\nthe review with highest predicted probability of being positive is: \\n\\n\",X_test.iloc[int(most_pos[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
